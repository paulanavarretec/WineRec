{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wineRec-OneHotEncoding.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulanavarretec/WineRec/blob/master/wineRec_OneHotEncoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zIrB1qdq90HC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Example dummy data from Rendle 2010 \n",
        "# http://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf\n",
        "# Variables categoricas (Users, Wines, Last Rated) pasaron por one-hot-encoding \n",
        "\n",
        "x_data = np.matrix([\n",
        "#     Users  |     Wines      |    Wine Ratings    | Time | Last Wines Rated\n",
        "#    A  B  C | W1  W2  W3  W4 | W1   W2   W3   W4  |      | W1  W2  W3  W3\n",
        "    [1, 0, 0,  1,  0,  0,  0,   0.3, 0.3, 0.3, 0,     13,   0,  0,  0,  0 ],\n",
        "    [1, 0, 0,  0,  1,  0,  0,   0.3, 0.3, 0.3, 0,     14,   1,  0,  0,  0 ],\n",
        "    [1, 0, 0,  0,  0,  1,  0,   0.3, 0.3, 0.3, 0,     16,   0,  1,  0,  0 ],\n",
        "    [0, 1, 0,  0,  0,  1,  0,   0,   0,   0.5, 0.5,   5,    0,  0,  0,  0 ],\n",
        "    [0, 1, 0,  0,  0,  0,  1,   0,   0,   0.5, 0.5,   8,    0,  0,  1,  0 ],\n",
        "    [0, 0, 1,  1,  0,  0,  0,   0.5, 0,   0.5, 0,     9,    0,  0,  0,  0 ],\n",
        "    [0, 0, 1,  0,  0,  1,  0,   0.5, 0,   0.5, 0,     12,   1,  0,  0,  0 ]\n",
        "])\n",
        "\n",
        "# ratings\n",
        "y_data = np.array([5, 3, 1, 4, 5, 1, 5])\n",
        "\n",
        "# Agregamos un eje para que funcione Tensorflow.\n",
        "y_data.shape += (1, )\n",
        "\n",
        "import tensorflow as tf\n",
        "n, p = x_data.shape\n",
        "\n",
        "# numero de latent factors\n",
        "k = 5\n",
        "\n",
        "# design matrix\n",
        "X = tf.placeholder('float', shape=[n, p])\n",
        "# target vector\n",
        "y = tf.placeholder('float', shape=[n, 1])\n",
        "\n",
        "# bias y weights\n",
        "w0 = tf.Variable(tf.zeros([1]))\n",
        "W = tf.Variable(tf.zeros([p]))\n",
        "\n",
        "# interaction factors, inicializados de forma aleatoria \n",
        "V = tf.Variable(tf.random_normal([k, p], stddev=0.01))\n",
        "\n",
        "# estimación de y, inicializada en 0.\n",
        "y_hat = tf.Variable(tf.zeros([n, 1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sBsXhd7TEDL-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usamos placeholders para los inputs y targets. Los datos actuales se asignarán en el runtime de la sesión. X e Y no serán modificados por el backend; Usamos variables para almacenar bias, weights y factor layers. Estos son los parámetros que se actualizarán al ajustar el modelo.\n",
        "\n",
        "En el siguiente código, computamos WX y usamos reduce_sum() para agregar las filas del Tensor resultante (axis 1). keep_dims está seteado en True para asegurar que las dimensiones input/output se respeten."
      ]
    },
    {
      "metadata": {
        "id": "YSjfrLr4Kh_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_terms = tf.add(w0,\n",
        "        \ttf.reduce_sum(\n",
        "          tf.multiply(W, X), 1, keepdims=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N9zqR5c_LS9l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En chunk anterior implementamos simplemente una regresion lineal. Hacemos lo mismo con los términos de interacción."
      ]
    },
    {
      "metadata": {
        "id": "hB2KZfheLRXD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "interactions = (tf.multiply(0.5,\n",
        "                tf.reduce_sum(\n",
        "                    tf.subtract(\n",
        "                        tf.pow( tf.matmul(X, tf.transpose(V)), 2),\n",
        "                        tf.matmul(tf.pow(X, 2), tf.transpose(tf.pow(V, 2)))),\n",
        "                    1, keep_dims=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6tg04B3M4VP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Y agregamos todo para obtener el target estimado."
      ]
    },
    {
      "metadata": {
        "id": "Sgi21PLdNAKK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_hat = tf.add(linear_terms, interactions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OXHMxDLFNSX6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Como estamos resolviendo un problema de regresion, aprendemos los parámetros del modelo minimizando la suma de los residuos cuadráticos como función de pérdida. También agregamos un término de regularización para prevenir overfitting."
      ]
    },
    {
      "metadata": {
        "id": "4vBmJRc6OW0H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Función de pérdida como suma de cuadrados regularizada L2  sobre W y V\n",
        "lambda_w = tf.constant(0.001, name='lambda_w')\n",
        "lambda_v = tf.constant(0.001, name='lambda_v')\n",
        "\n",
        "l2_norm = (tf.reduce_sum(\n",
        "            tf.add(\n",
        "                tf.multiply(lambda_w, tf.pow(W, 2)),\n",
        "                tf.multiply(lambda_v, tf.pow(V, 2)))))\n",
        "\n",
        "error = tf.reduce_mean(tf.square(tf.subtract(y, y_hat)))\n",
        "loss = tf.add(error, l2_norm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T4zLA3UfOOzI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para entrenar el modelo declamos un optimizador y minimizamos la función de pérdida."
      ]
    },
    {
      "metadata": {
        "id": "t_eu56JsPJEd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eta = tf.constant(0.1)\n",
        "optimizer = tf.train.AdagradOptimizer(eta).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "goTSCjFIPaCN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Estamos listos para obtener el grafo y desplegarlo en el backend de Tensorflow. Usamos pythos context manager pata manejar la sesion."
      ]
    },
    {
      "metadata": {
        "id": "aEH0ZLCzPxaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "f9e22953-82a1-4f23-cb2c-fc3bcfd9698b"
      },
      "cell_type": "code",
      "source": [
        "# Muchas Iteraciones\n",
        "N_EPOCHS = 1000\n",
        "\n",
        "# Desplegar grafo\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        indices = np.arange(n)\n",
        "        np.random.shuffle(indices)\n",
        "        x_data, y_data = x_data[indices], y_data[indices]\n",
        "        sess.run(optimizer, feed_dict={X: x_data, y: y_data})\n",
        "\n",
        "    print('MSE: ', sess.run(error, feed_dict={X: x_data, y: y_data}))\n",
        "    print('Loss (regularized error):', sess.run(loss, feed_dict={X: x_data, y: y_data}))\n",
        "    print('Predictions:', sess.run(y_hat, feed_dict={X: x_data, y: y_data}))\n",
        "    print('Learnt weights:', sess.run(W, feed_dict={X: x_data, y: y_data}))\n",
        "    print('Learnt factors:', sess.run(V, feed_dict={X: x_data, y: y_data}))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE:  4.5705195e-07\n",
            "Loss (regularized error): 0.0031154503\n",
            "Predictions: [[3.0001822]\n",
            " [1.0004226]\n",
            " [4.9992223]\n",
            " [1.0009962]\n",
            " [4.9996285]\n",
            " [4.999851 ]\n",
            " [3.9988909]]\n",
            "Learnt weights: [ 0.15683964  0.18582082 -0.11557835 -0.01759121 -0.05105131  0.20488892\n",
            "  0.08483714 -0.0028634   0.09054252  0.07809868  0.14044799  0.11401302\n",
            "  0.1677825  -0.16010605  0.08483714  0.        ]\n",
            "Learnt factors: [[-0.03877404  0.09972517 -0.02663375 -0.02762474 -0.11602374  0.05021128\n",
            "   0.06052936 -0.02106447 -0.03125477  0.02357763  0.09259289  0.05842411\n",
            "   0.05749567 -0.18113753  0.06019074 -0.00141657]\n",
            " [ 0.15471348  0.22781421 -0.09609849  0.13426377 -0.2403505   0.20543666\n",
            "   0.04828157  0.02070697  0.08827759  0.09127898  0.19516642  0.24714474\n",
            "   0.24685891 -0.3831636   0.06615476 -0.00153511]\n",
            " [ 0.10873464  0.21694219 -0.14482094  0.10426582 -0.2676071   0.17748334\n",
            "   0.04517152 -0.02715301  0.07373484  0.05430392  0.18379144  0.24976592\n",
            "   0.20171249 -0.3793244   0.05433233 -0.01011759]\n",
            " [ 0.12126153  0.21105057 -0.14552431  0.13056841 -0.26526293  0.18605919\n",
            "   0.03061874  0.00085359  0.0690724   0.05680273  0.1720788   0.25048792\n",
            "   0.2068271  -0.3830043   0.02884758  0.00844025]\n",
            " [ 0.05967973  0.16945113 -0.1312849   0.05269478 -0.2638647   0.13917562\n",
            "   0.0342277  -0.03543615  0.04515457  0.03081632  0.15294474  0.20052183\n",
            "   0.1542964  -0.33870348  0.02751925  0.00189404]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J8aB9XdbSM9f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En cada iteración (hasta N_EPOCHS) ejecutamos el optimizador, el cual recalcula los parametros del modelo por el método de descenso del gradiente. Notar que estamos moviendo datos desde el espacio de memoria de Python al de backend C++ de Tensorflow  a través de feed_dict={}.\n",
        "Como estamos trabajando con un set reducido de datos exprimentales podemos entregar el dataset todo de una vez. En la práctica, querremos trabajar con mini batches (ej. usando un generador sobre el input). Podemos mezclar los datos (np.random.shuffle) para evitar sesgar el gradiente."
      ]
    },
    {
      "metadata": {
        "id": "-nH_62KrToPL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experimentos"
      ]
    },
    {
      "metadata": {
        "id": "SxGWlDpwXfeK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para setear un benchmark  del performance en general del modelo, entrenamos y testeamos en el dataset porcionado en training y test (70%-30%). El objetivo es predecir el rating para cada vino. Luego del aplicar one-hot-encoding a las variables categóricas, obtendemos una design matrix de 90570×2623 [Corregir] para el training set, y de 90570×2623[Corregir] para el test set.\n"
      ]
    },
    {
      "metadata": {
        "id": "Mdz6p5IXPZYV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}